{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "%matplotlib inline\nfrom preamble import *\nplt.rcParams['image.cmap'] = \"gray\"",
      "metadata": {
        "hide_input": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Machine Learning Application in Finance\n# &emsp; BAN437, Summer 2021\n\n### &emsp; &emsp; Professor: Philip Sun\n### &emsp; &emsp; Email: philip.sun@faculty.hult.edu\n### &emsp; &emsp; Last Modified: 5/21/2021\n\n___\n\n## Chapter 3: Unsupervised Learning\n### 3.1 Preview\n\nAdapted from the reference text:\nText: \"Introduction to Machine Learning with Python\" by Andreas C. Muller & Sarah Guido, 2017 Edition, O'Reilly; ISBN: 978-1-449-36941-5## Supervised Learning",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mglearn.plots.plot_scaling()",
      "metadata": {
        "hide_input": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Different Kinds of Preprocessing\n#### Applying Data Transformations",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\ncancer = load_breast_cancer()\n\nX_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n                                                    random_state=1)\nprint(X_train.shape)\nprint(X_test.shape)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "scaler.fit(X_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# transform data\nX_train_scaled = scaler.transform(X_train)\n# print dataset properties before and after scaling\nprint(\"transformed shape: {}\".format(X_train_scaled.shape))\nprint(\"per-feature minimum before scaling:\\n {}\".format(X_train.min(axis=0)))\nprint(\"per-feature maximum before scaling:\\n {}\".format(X_train.max(axis=0)))\nprint(\"per-feature minimum after scaling:\\n {}\".format(\n    X_train_scaled.min(axis=0)))\nprint(\"per-feature maximum after scaling:\\n {}\".format(\n    X_train_scaled.max(axis=0)))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# transform test data\nX_test_scaled = scaler.transform(X_test)\n# print test data properties after scaling\nprint(\"per-feature minimum after scaling:\\n{}\".format(X_test_scaled.min(axis=0)))\nprint(\"per-feature maximum after scaling:\\n{}\".format(X_test_scaled.max(axis=0)))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Scaling training and test data the same way",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import make_blobs\n# make synthetic data\nX, _ = make_blobs(n_samples=50, centers=5, random_state=4, cluster_std=2)\n# split it into training and test sets\nX_train, X_test = train_test_split(X, random_state=5, test_size=.1)\n\n# plot the training and test sets\nfig, axes = plt.subplots(1, 3, figsize=(13, 4))\naxes[0].scatter(X_train[:, 0], X_train[:, 1],\n                color=mglearn.cm2(0), label=\"Training set\", s=60)\naxes[0].scatter(X_test[:, 0], X_test[:, 1], marker='^',\n                color=mglearn.cm2(1), label=\"Test set\", s=60)\naxes[0].legend(loc='upper left')\naxes[0].set_title(\"Original Data\")\n\n# scale the data using MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# visualize the properly scaled data\naxes[1].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1],\n                color=mglearn.cm2(0), label=\"Training set\", s=60)\naxes[1].scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], marker='^',\n                color=mglearn.cm2(1), label=\"Test set\", s=60)\naxes[1].set_title(\"Scaled Data\")\n\n# rescale the test set separately\n# so test set min is 0 and test set max is 1\n# DO NOT DO THIS! For illustration purposes only.\ntest_scaler = MinMaxScaler()\ntest_scaler.fit(X_test)\nX_test_scaled_badly = test_scaler.transform(X_test)\n\n# visualize wrongly scaled data\naxes[2].scatter(X_train_scaled[:, 0], X_train_scaled[:, 1],\n                color=mglearn.cm2(0), label=\"training set\", s=60)\naxes[2].scatter(X_test_scaled_badly[:, 0], X_test_scaled_badly[:, 1],\n                marker='^', color=mglearn.cm2(1), label=\"test set\", s=60)\naxes[2].set_title(\"Improperly Scaled Data\")\n\nfor ax in axes:\n    ax.set_xlabel(\"Feature 0\")\n    ax.set_ylabel(\"Feature 1\")\nfig.tight_layout()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# calling fit and transform in sequence (using method chaining)\nX_scaled = scaler.fit(X_train).transform(X_train)\n\n\n# same result, but more efficient computation\nX_scaled_d = scaler.fit_transform(X_train)\n\nprint(X_scaled[0:6,:])\nprint(X_scaled_d[0:6,:])\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### The effect of preprocessing on supervised learning",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.svm import SVC\n\nX_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,\n                                                    random_state=0)\n\nsvm = SVC(C=100)\nsvm.fit(X_train, y_train)\nprint(\"Test set accuracy: {:.2f}\".format(svm.score(X_test, y_test)))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# preprocessing using 0-1 scaling\nscaler = MinMaxScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# learning an SVM on the scaled training data\nsvm.fit(X_train_scaled, y_train)\n\n# scoring on the scaled test set\nprint(\"Scaled test set accuracy: {:.2f}\".format(\n    svm.score(X_test_scaled, y_test)))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# preprocessing using zero mean and unit variance scaling\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# learning an SVM on the scaled training data\nsvm.fit(X_train_scaled, y_train)\n\n# scoring on the scaled test set\nprint(\"SVM test accuracy: {:.2f}\".format(svm.score(X_test_scaled, y_test)))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1 PreviewDimensionality Reduction, Feature Extraction and Manifold Learning\n#### Principal Component Analysis (PCA)",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "mglearn.plots.plot_pca_illustration()",
      "metadata": {
        "hide_input": false,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "##### Applying PCA to the cancer dataset for visualization",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "fig, axes = plt.subplots(15, 2, figsize=(10, 20))\nmalignant = cancer.data[cancer.target == 0]\nbenign = cancer.data[cancer.target == 1]\n\nax = axes.ravel()\n\nfor i in range(30):\n    _, bins = np.histogram(cancer.data[:, i], bins=50)\n    ax[i].hist(malignant[:, i], bins=bins, color=mglearn.cm3(0), alpha=.5)\n    ax[i].hist(benign[:, i], bins=bins, color=mglearn.cm3(2), alpha=.5)\n    ax[i].set_title(cancer.feature_names[i])\n    ax[i].set_yticks(())\nax[0].set_xlabel(\"Feature magnitude\")\nax[0].set_ylabel(\"Frequency\")\nax[0].legend([\"malignant\", \"benign\"], loc=\"best\")\nfig.tight_layout()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import load_breast_cancer\ncancer = load_breast_cancer()\n\nscaler = StandardScaler()\nscaler.fit(cancer.data)\nX_scaled = scaler.transform(cancer.data)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.decomposition import PCA\n# keep the first two principal components of the data\npca = PCA(n_components=3)\n# fit PCA model to beast cancer data\npca.fit(X_scaled)\n\n# transform data onto the first two principal components\nX_pca = pca.transform(X_scaled)\nprint(\"Original shape: {}\".format(str(X_scaled.shape)))\nprint(\"Reduced shape: {}\".format(str(X_pca.shape)))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# plot first vs. second principal component, colored by class\nplt.figure(figsize=(8, 8))\nmglearn.discrete_scatter(X_pca[:, 0], X_pca[:, 1], cancer.target)\nplt.legend(cancer.target_names, loc=\"best\")\nplt.gca().set_aspect(\"equal\")\nplt.xlabel(\"First principal component\")\nplt.ylabel(\"Second principal component\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(\"PCA component shape: {}\".format(pca.components_.shape))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(\"PCA components:\\n{}\".format(pca.components_))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.matshow(pca.components_, cmap='viridis')\nplt.yticks([0, 1], [\"First component\", \"Second component\"])\nplt.colorbar()\nplt.xticks(range(len(cancer.feature_names)),\n           cancer.feature_names, rotation=60, ha='left')\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Principal components\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}