{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 2 \n",
    "# &emsp; BAN437, Summer 2021\n",
    "\n",
    "### &emsp; &emsp; Professor: Philip Sun\n",
    "### &emsp; &emsp; Email: philip.sun@faculty.hult.edu\n",
    "### &emsp; &emsp; Last Modified: 5/19/2021\n",
    "\n",
    "___\n",
    "\n",
    "## Bankruptcy, Logistic Regression, and Neural Networks\n",
    "\n",
    "\n",
    "## &emsp; Ex1 Predict Company Bankcruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt?</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>operating gross margin</th>\n",
       "      <th>realized sales gross margin</th>\n",
       "      <th>operating profit rate</th>\n",
       "      <th>tax Pre-net interest rate</th>\n",
       "      <th>after-tax net interest rate</th>\n",
       "      <th>non-industry income and expenditure/revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>one if total liabilities exceeds total assets zero otherwise</th>\n",
       "      <th>net income to total assets</th>\n",
       "      <th>No-credit interval</th>\n",
       "      <th>Gross profit to Sales</th>\n",
       "      <th>Net income to stockholder's Equity</th>\n",
       "      <th>liability to equity</th>\n",
       "      <th>Degree of financial leverage (DFL)</th>\n",
       "      <th>Interest coverage ratio( Interest expense to EBIT )</th>\n",
       "      <th>one if net income was negative for the last two year zero otherwise</th>\n",
       "      <th>equity to liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.539468</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.604462</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.623620</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.566193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>0.598306</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.278132</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.566018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0</td>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.610444</td>\n",
       "      <td>0.610213</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.809317</td>\n",
       "      <td>0.303512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.624156</td>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0</td>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.559911</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.607846</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.277547</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>0</td>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.801987</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.313415</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.626680</td>\n",
       "      <td>0.627408</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.275114</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.565167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6819 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
       "0             1                                           0.370594          \n",
       "1             1                                           0.464291          \n",
       "2             1                                           0.426071          \n",
       "3             1                                           0.399844          \n",
       "4             1                                           0.465022          \n",
       "...         ...                                                ...          \n",
       "6814          0                                           0.493687          \n",
       "6815          0                                           0.475162          \n",
       "6816          0                                           0.472725          \n",
       "6817          0                                           0.506264          \n",
       "6818          0                                           0.493053          \n",
       "\n",
       "       ROA(A) before interest and % after tax  \\\n",
       "0                                    0.424389   \n",
       "1                                    0.538214   \n",
       "2                                    0.499019   \n",
       "3                                    0.451265   \n",
       "4                                    0.538432   \n",
       "...                                       ...   \n",
       "6814                                 0.539468   \n",
       "6815                                 0.538269   \n",
       "6816                                 0.533744   \n",
       "6817                                 0.559911   \n",
       "6818                                 0.570105   \n",
       "\n",
       "       ROA(B) before interest and depreciation after tax  \\\n",
       "0                                              0.405750    \n",
       "1                                              0.516730    \n",
       "2                                              0.472295    \n",
       "3                                              0.457733    \n",
       "4                                              0.522298    \n",
       "...                                                 ...    \n",
       "6814                                           0.543230    \n",
       "6815                                           0.524172    \n",
       "6816                                           0.520638    \n",
       "6817                                           0.554045    \n",
       "6818                                           0.549548    \n",
       "\n",
       "       operating gross margin   realized sales gross margin  \\\n",
       "0                    0.601457                      0.601457   \n",
       "1                    0.610235                      0.610235   \n",
       "2                    0.601450                      0.601364   \n",
       "3                    0.583541                      0.583541   \n",
       "4                    0.598783                      0.598783   \n",
       "...                       ...                           ...   \n",
       "6814                 0.604455                      0.604462   \n",
       "6815                 0.598308                      0.598308   \n",
       "6816                 0.610444                      0.610213   \n",
       "6817                 0.607850                      0.607850   \n",
       "6818                 0.627409                      0.627409   \n",
       "\n",
       "       operating profit rate   tax Pre-net interest rate  \\\n",
       "0                   0.998969                    0.796887   \n",
       "1                   0.998946                    0.797380   \n",
       "2                   0.998857                    0.796403   \n",
       "3                   0.998700                    0.796967   \n",
       "4                   0.998973                    0.797366   \n",
       "...                      ...                         ...   \n",
       "6814                0.998992                    0.797409   \n",
       "6815                0.998992                    0.797414   \n",
       "6816                0.998984                    0.797401   \n",
       "6817                0.999074                    0.797500   \n",
       "6818                0.998080                    0.801987   \n",
       "\n",
       "       after-tax net interest rate  \\\n",
       "0                         0.808809   \n",
       "1                         0.809301   \n",
       "2                         0.808388   \n",
       "3                         0.808966   \n",
       "4                         0.809304   \n",
       "...                            ...   \n",
       "6814                      0.809331   \n",
       "6815                      0.809327   \n",
       "6816                      0.809317   \n",
       "6817                      0.809399   \n",
       "6818                      0.813800   \n",
       "\n",
       "       non-industry income and expenditure/revenue  ...  \\\n",
       "0                                         0.302646  ...   \n",
       "1                                         0.303556  ...   \n",
       "2                                         0.302035  ...   \n",
       "3                                         0.303350  ...   \n",
       "4                                         0.303475  ...   \n",
       "...                                            ...  ...   \n",
       "6814                                      0.303510  ...   \n",
       "6815                                      0.303520  ...   \n",
       "6816                                      0.303512  ...   \n",
       "6817                                      0.303498  ...   \n",
       "6818                                      0.313415  ...   \n",
       "\n",
       "      one if total liabilities exceeds total assets zero otherwise  \\\n",
       "0                                                     0              \n",
       "1                                                     0              \n",
       "2                                                     0              \n",
       "3                                                     0              \n",
       "4                                                     0              \n",
       "...                                                 ...              \n",
       "6814                                                  0              \n",
       "6815                                                  0              \n",
       "6816                                                  0              \n",
       "6817                                                  0              \n",
       "6818                                                  0              \n",
       "\n",
       "      net income to total assets  No-credit interval  Gross profit to Sales  \\\n",
       "0                       0.716845            0.622879               0.601453   \n",
       "1                       0.795297            0.623652               0.610237   \n",
       "2                       0.774670            0.623841               0.601449   \n",
       "3                       0.739555            0.622929               0.583538   \n",
       "4                       0.795016            0.623521               0.598782   \n",
       "...                          ...                 ...                    ...   \n",
       "6814                    0.799927            0.623620               0.604455   \n",
       "6815                    0.799748            0.623931               0.598306   \n",
       "6816                    0.797778            0.624156               0.610441   \n",
       "6817                    0.811808            0.623957               0.607846   \n",
       "6818                    0.815956            0.626680               0.627408   \n",
       "\n",
       "      Net income to stockholder's Equity  liability to equity  \\\n",
       "0                               0.827890             0.290202   \n",
       "1                               0.839969             0.283846   \n",
       "2                               0.836774             0.290189   \n",
       "3                               0.834697             0.281721   \n",
       "4                               0.839973             0.278514   \n",
       "...                                  ...                  ...   \n",
       "6814                            0.840359             0.279606   \n",
       "6815                            0.840306             0.278132   \n",
       "6816                            0.840138             0.275789   \n",
       "6817                            0.841084             0.277547   \n",
       "6818                            0.841019             0.275114   \n",
       "\n",
       "      Degree of financial leverage (DFL)  \\\n",
       "0                               0.026601   \n",
       "1                               0.264577   \n",
       "2                               0.026555   \n",
       "3                               0.026697   \n",
       "4                               0.024752   \n",
       "...                                  ...   \n",
       "6814                            0.027064   \n",
       "6815                            0.027009   \n",
       "6816                            0.026791   \n",
       "6817                            0.026822   \n",
       "6818                            0.026793   \n",
       "\n",
       "      Interest coverage ratio( Interest expense to EBIT )  \\\n",
       "0                                              0.564050     \n",
       "1                                              0.570175     \n",
       "2                                              0.563706     \n",
       "3                                              0.564663     \n",
       "4                                              0.575617     \n",
       "...                                                 ...     \n",
       "6814                                           0.566193     \n",
       "6815                                           0.566018     \n",
       "6816                                           0.565158     \n",
       "6817                                           0.565302     \n",
       "6818                                           0.565167     \n",
       "\n",
       "      one if net income was negative for the last two year zero otherwise  \\\n",
       "0                                                     1                     \n",
       "1                                                     1                     \n",
       "2                                                     1                     \n",
       "3                                                     1                     \n",
       "4                                                     1                     \n",
       "...                                                 ...                     \n",
       "6814                                                  1                     \n",
       "6815                                                  1                     \n",
       "6816                                                  1                     \n",
       "6817                                                  1                     \n",
       "6818                                                  1                     \n",
       "\n",
       "      equity to liability  \n",
       "0                0.016469  \n",
       "1                0.020794  \n",
       "2                0.016474  \n",
       "3                0.023982  \n",
       "4                0.035490  \n",
       "...                   ...  \n",
       "6814             0.029890  \n",
       "6815             0.038284  \n",
       "6816             0.097649  \n",
       "6817             0.044009  \n",
       "6818             0.233902  \n",
       "\n",
       "[6819 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import bankruptcy data\n",
    "# download the following data file from mycourse page, and store it in the same directory as the notebook file\n",
    "csv_file='CompanyBankruptcy_Clean.csv'\n",
    "df_bankruptcy=pd.read_csv(csv_file, index_col=0)\n",
    "df_bankruptcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw scatter plot(s) for class slides:\n",
    "xlabel=['Interest coverage ratio( Interest expense to EBIT )', 'Degree of financial leverage (DFL)', 'liability to equity']\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "for label in xlabel:\n",
    "    x=df_bankruptcy[label]\n",
    "    y=df_bankruptcy['Bankrupt?']\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.scatter(x, y)\n",
    "    plt.title('Bankruptcy')\n",
    "    plt.xlabel(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute and output some summary statistics\n",
    "\n",
    "def stat_summary(df_data, to_print):\n",
    "    stat_count=len(df_data.index)\n",
    "    stat_mean=np.mean(df_data, axis=0)\n",
    "    stat_std=np.std(df_data, axis=0)\n",
    "    stat_max=np.max(df_data, axis=0)\n",
    "    stat_90pct=np.percentile(df_data, 90, axis=0)\n",
    "    stat_75pct=np.percentile(df_data, 75, axis=0)\n",
    "    stat_25pct=np.percentile(df_data, 25, axis=0)\n",
    "    stat_10pct=np.percentile(df_data, 10, axis=0)\n",
    "    stat_median=np.median(df_data, axis=0)\n",
    "    stat_min=np.min(df_data, axis=0)\n",
    "\n",
    "        \n",
    "    #return\n",
    "    df_stat_summary=pd.DataFrame({'count': stat_count,\n",
    "                    'mean': stat_mean,\n",
    "                    'stdev': stat_std,\n",
    "                    'stat_max': stat_max,\n",
    "                    'stat_90pct': stat_90pct,\n",
    "                    'stat_75pct': stat_75pct,\n",
    "                    'stat_media': stat_median,\n",
    "                    'stat_25pct': stat_25pct,\n",
    "                    'stat_10pct': stat_10pct,\n",
    "                    'stat_min': stat_min} ,\n",
    "                     index = df_data.columns)\n",
    "\n",
    "    #print?\n",
    "    if to_print:\n",
    "        print(df_stat_summary)\n",
    "        \n",
    "    return df_stat_summary\n",
    "# end of function stat_summary\n",
    "\n",
    "\n",
    "df_stat=stat_summary(df_bankruptcy, False)\n",
    "#df_stat.to_csv('csv_out.csv') # this is the .csv output file.  open to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE, the dataset has been cleaned to remove some outliers.  following were codes used to clean the original data from kaggle.com\n",
    "# csv_file='CompanyBankruptcy.csv'\n",
    "# df_bankruptcy=pd.read_csv(csv_file, index_col=0)\n",
    "# df_bankruptcy.drop(df_bankruptcy.columns[df_stat['stat_max']>1.0e+8], axis=1, inplace=True)\n",
    "# df_bankruptcy.dropna\n",
    "# df_bankruptcy.to_csv('CompanyBankruptcy_Clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first split the data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=np.array(df_bankruptcy.iloc[:,1:]) # get features from df, convert to array for easy numerical operation\n",
    "y=np.array(df_bankruptcy.iloc[:,0]) # get target, note y=1 for bankruptcy, 0 for no bankruptcy\n",
    "\n",
    "# splitting into training, and test\n",
    "# note: use stratify as y=1 is rare (~3% of total observation). stratify ensures that positives are split proportionally\n",
    "Xtra, Xtest, ytra, ytest = train_test_split(X, y, stratify=y, test_size=0.20, random_state=0)\n",
    "# further split training into train and validation\n",
    "Xtra, Xval, ytra, yval = train_test_split(Xtra, ytra, stratify=ytra, test_size=0.25, random_state=0)\n",
    "# final split is 60:20:20, tra:val:test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score (accuracy):   0.9709117575164996\n",
      "validation score (accuracy):   0.967008797653959\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "Logit_Reg=LogisticRegression(random_state=0).fit(Xtra, ytra)\n",
    "\n",
    "print('training score (accuracy):  ', Logit_Reg.score(Xtra,ytra))\n",
    "print('validation score (accuracy):  ', Logit_Reg.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function, i.e. the linear function theta'*x: \n",
      " [-2.80896605 -4.19877811 -4.32733405 ... -6.34150291 -5.46659652\n",
      " -4.66269985] \n",
      "\n",
      "Decision function min: -10.77 max: 4.17 \n",
      "\n",
      "Predicition probability, i.e. the sigmoid function g(theta*x): \n",
      " [0.94315841 0.98520817 0.98696934 ... 0.99824145 0.99579219 0.99064736] \n",
      "\n",
      "Predicition probability min: 0.02 max: 1.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a Look at Prediction\n",
    "decfun_val=Logit_Reg.decision_function(Xval)\n",
    "print(\"Decision function, i.e. the linear function theta'*x: \\n\", decfun_val, \"\\n\")\n",
    "print(\"Decision function min: {:.2f} max: {:.2f} \\n\".format(np.min(decfun_val), np.max(decfun_val)))\n",
    "\n",
    "prob_val=Logit_Reg.predict_proba(Xval)\n",
    "print(\"Predicition probability, i.e. the sigmoid function g(theta*x): \\n\", prob_val[:,0], \"\\n\")\n",
    "print(\"Predicition probability min: {:.2f} max: {:.2f} \\n\".format(np.min(prob_val[:,0]), np.max(prob_val[:,0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Neural Network (Deep Learning)\n",
    "In sklearn, the neural_network package is pretty good for small dataset.  for more computational demanding tasks check out kera, tensorflow, or other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score (accuracy):   0.9689562454167685\n",
      "validation score (accuracy):   0.969208211143695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# there are many parameters here\n",
    "# * solver (previously algorithm), default 'adam' does a good job.  other options like 'lbfgs' more robust but slower\n",
    "# * activation is the function applied, there is 'tanh' is similar to sigmoid, \n",
    "#     it uses sigmoid tangent function betwee -1 and +1\n",
    "# * max_iter gives the maximimun iteration (of gradient descent).  if opt does not converge, it will stop at max_iter.\n",
    "#     we will start with 1000, and will increase to 10,000\n",
    "# * alpha is the regularization parameter. higher alpha, means more regularization (i.e. shrink coef more)\n",
    "# * hidden_layer, specifies how many hidden layer and how many nodes per layer.\n",
    "\n",
    "nn_01 = MLPClassifier(solver='adam', activation='tanh', \n",
    "                      max_iter=1000, alpha=0.01, random_state=0, \n",
    "                      hidden_layer_sizes=[10, 10]).fit(Xtra, ytra)\n",
    "\n",
    "print('training score (accuracy):  ', nn_01.score(Xtra,ytra))\n",
    "print('validation score (accuracy):  ', nn_01.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score (accuracy):   0.9689562454167685\n",
      "validation score (accuracy):   0.969208211143695\n"
     ]
    }
   ],
   "source": [
    "# what if we add a layer\n",
    "nn_02 = MLPClassifier(solver='adam', activation='tanh', \n",
    "                      max_iter=10000, alpha=1, random_state=0, \n",
    "                      hidden_layer_sizes=[16, 8, 4]).fit(Xtra, ytra)\n",
    "\n",
    "print('training score (accuracy):  ', nn_01.score(Xtra,ytra))\n",
    "print('validation score (accuracy):  ', nn_01.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.a (graded) \n",
    "Run Neural Network fitting with 3 hidden layers with multiple alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0003</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0030</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0300</th>\n",
       "      <td>0.969201</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.969208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3000</th>\n",
       "      <td>0.968223</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0000</th>\n",
       "      <td>0.970667</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0000</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train validation\n",
       "0.0001  0.969934   0.970674\n",
       "0.0003  0.969934   0.970674\n",
       "0.0010  0.969934   0.970674\n",
       "0.0030  0.969934   0.970674\n",
       "0.0100  0.969934   0.970674\n",
       "0.0300  0.969201   0.970674\n",
       "0.1000  0.969934   0.969208\n",
       "0.3000  0.968223   0.967742\n",
       "1.0000  0.970667   0.967742\n",
       "3.0000  0.967734   0.967742"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through alpha in a range and collect scores, and print at the end. \n",
    "alpharange=[0.0001, 0.0003, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3]\n",
    "hidden_layer=[16, 8, 4]\n",
    "df_accuracy=pd.DataFrame([], index=alpharange, columns=['train','validation'])\n",
    "for a in alpharange:\n",
    "    # complete the code to fit MLPClassifier in this for loop\n",
    "    nn_03 = MLPClassifier(solver='adam', activation='tanh', random_state=0,\n",
    "                        hidden_layer_sizes=hidden_layer, alpha=a).fit(Xtra,ytra)\n",
    "    \n",
    "    # collect results, i.e. prediction scores\n",
    "    df_accuracy.loc[a,:]=[nn_03.score(Xtra,ytra),nn_03.score(Xval,yval)]\n",
    "    \n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.b (graded)\n",
    "run Neural Network fitting with randomized initialization, and collect the accuracy scores in a dataframe indexed by the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969934</td>\n",
       "      <td>0.970674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.970178</td>\n",
       "      <td>0.969208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.96969</td>\n",
       "      <td>0.969208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.967734</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.969445</td>\n",
       "      <td>0.968475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train validation\n",
       "0  0.969934   0.970674\n",
       "1  0.967734   0.967742\n",
       "2  0.970178   0.969208\n",
       "3  0.967734   0.967742\n",
       "4  0.967734   0.967742\n",
       "5  0.967734   0.967742\n",
       "6  0.967734   0.967742\n",
       "7   0.96969   0.969208\n",
       "8  0.967734   0.967742\n",
       "9  0.969445   0.968475"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterate through alpha in a range and collect scores, and print at the end. \n",
    "alpha_value=0.01\n",
    "hidden_layer=[16, 8, 4]\n",
    "df_accuracy=pd.DataFrame([], index=range(10), columns=['train','validation'])\n",
    "for i in range(10):\n",
    "    # complete the code to fit MLPClassifier in this for loop\n",
    "    nn_04 = MLPClassifier(activation='tanh', random_state=i, hidden_layer_sizes=hidden_layer, alpha=alpha_value).fit(Xtra, ytra)\n",
    "    \n",
    "    # collect results, i.e. prediction scores\n",
    "    df_accuracy.loc[i,:]=[nn_04.score(Xtra,ytra), nn_04.score(Xval,yval)]\n",
    "    \n",
    "df_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2.c (optional)\n",
    "compute a balanced F1 Score and report in addition to accuracy score (see Wikipedia entry below for definition)\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score: 0.9706744868035191\n",
      "tp: 10\n",
      "fp: 6\n",
      "fn: 34\n",
      "tn: 1314\n",
      "F1: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Hint: make a prediction from the model. then count the number of true/false positives and true/false negatives etc.\n",
    "\n",
    "nn_05 = MLPClassifier(solver='adam', activation='tanh', random_state=0,\n",
    "                        hidden_layer_sizes=hidden_layer, alpha=0.0001).fit(Xtra,ytra)\n",
    "\n",
    "\n",
    "predictions = nn_05.predict(Xval)\n",
    "df_prediction=pd.DataFrame(predictions, columns=['Prediction'])\n",
    "df_prediction['Target']=yval\n",
    "\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "for i in df_prediction.iterrows():\n",
    "\n",
    "    pred = i[1]['Prediction']\n",
    "    actual = i[1]['Target']\n",
    "\n",
    "    tp += 1 if pred == actual and pred == 1 else 0\n",
    "    fp += 1 if pred != actual and pred == 1 else 0\n",
    "    fn += 1 if pred != actual and pred == 0 else 0\n",
    "    tn += 1 if pred == actual and pred == 0 else 0\n",
    "\n",
    "\n",
    "f1 = 2*tp/(2*tp+fp+fn)\n",
    "\n",
    "print(\"Total Score: {}\".format(nn_05.score(Xval, yval)))\n",
    "print(\"tp: {}\\nfp: {}\\nfn: {}\\ntn: {}\".format(tp, fp, fn, tn))\n",
    "print(\"F1: {}\".format(f1))\n",
    "#finally compute F1 as F1=2*tp/(2*tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
